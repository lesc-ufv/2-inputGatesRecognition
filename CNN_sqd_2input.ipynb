{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_sqd_2input.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install git+git://github.com/lesc-ufv/cad4u.git &> /dev/null\n",
        "%cd /content\n",
        "!git clone https://github.com/dalilavieira/CNN.git &> /dev/null"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAdGQUGaAQf3",
        "outputId": "13ea7188-7f27-4928-892a-d67ae467b5f8"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nsn7Z3f_jkc",
        "outputId": "02b7b361-7442-478a-868f-7dff95eda726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "def dataset(again):\n",
        "    #img = cv2.imread('a.png')\n",
        "    use = []\n",
        "    test_labels, train_labels, test_images, train_images = [], [], [], []\n",
        "\n",
        "    flag = 0    \n",
        "    for _,_,files in os.walk('/content/CNN/-0.28_2/and'):\n",
        "        #print(files)\n",
        "        for f in files:\n",
        "        \tif f.find('png') != -1 and f.find('and') != -1 and v_and:\n",
        "        \t\t#print(f)\n",
        "        \t\ts = '/content/CNN/-0.28_2/and/'+f\n",
        "        \t\tuse.append(s)\n",
        "        \t\tif flag % 4 == 0:\n",
        "        \t\t\ttest_labels.append(1)\n",
        "        \t\telse:\n",
        "        \t\t\ttrain_labels.append(1)\n",
        "        \t\tflag += 1\n",
        "\n",
        "    flag = 0    \t\t\n",
        "    for _,_,files in os.walk('/content/CNN/-0.28_2/or'):\n",
        "        #print(files)\n",
        "        for f in files:\n",
        "        \tif f.find('png') != -1 and f.find('or') != -1 and v_or:\n",
        "        \t\ts = '/content/CNN/-0.28_2/or/'+f\n",
        "        \t\tuse.append(s)\n",
        "        \t\tif flag % 4 == 0:\n",
        "        \t\t\ttest_labels.append(2)\n",
        "        \t\telse:\n",
        "        \t\t\ttrain_labels.append(2)\n",
        "        \t\tflag += 1\n",
        "\n",
        "    flag = 0   \t\t\n",
        "    for _,_,files in os.walk('/content/CNN/-0.28_2/xor'):\n",
        "        #print(files)\n",
        "        for f in files:\n",
        "        \tif f.find('png') != -1 and f.find('xor') != -1 and v_xor:\n",
        "        \t\ts = '/content/CNN/-0.28_2/xor/'+f\n",
        "        \t\tuse.append(s)\n",
        "        \t\tif flag % 4 == 0:\n",
        "        \t\t\ttest_labels.append(3)\n",
        "        \t\telse:\n",
        "        \t\t\ttrain_labels.append(3)\n",
        "        \t\tflag += 1\n",
        "\n",
        "\n",
        "    flag = 0   \t\t\n",
        "    for _,_,files in os.walk('/content/CNN/-0.28_2/xnor'):\n",
        "        #print(files)\n",
        "        for f in files:\n",
        "        \tif f.find('png') != -1 and f.find('xnor') != -1 and v_xnor:\n",
        "        \t\ts = '/content/CNN/-0.28_2/xnor/'+f\n",
        "        \t\tuse.append(s)\n",
        "        \t\tv = 4\t\t\n",
        "        \t\tif again:\n",
        "        \t\t\tv = 3        \t\t\n",
        "        \t\tif flag % 4 == 0:\n",
        "        \t\t\ttest_labels.append(v)\n",
        "        \t\telse:\n",
        "        \t\t\ttrain_labels.append(v)\n",
        "        \t\tflag += 1\n",
        "\n",
        "    flag = 0   \t\t\n",
        "    for _,_,files in os.walk('/content/CNN/-0.28_2/nor'):\n",
        "        #print(files)\n",
        "        for f in files:\n",
        "        \tif f.find('png') != -1 and f.find('nor') != -1 and v_nor:\n",
        "        \t\ts = '/content/CNN/-0.28_2/nor/'+f\n",
        "        \t\tuse.append(s)\t\t\t\n",
        "        \t\tv = 5\t\t\n",
        "        \t\tif again:\n",
        "        \t\t\tv = 1\n",
        "        \t\tif flag % 4 == 0:\n",
        "        \t\t\ttest_labels.append(v)\n",
        "        \t\telse:\n",
        "        \t\t\ttrain_labels.append(v)\n",
        "        \t\tflag += 1\n",
        "\n",
        "    flag = 0   \t\t\n",
        "    for _,_,files in os.walk('/content/CNN/-0.28_2/nand'):\n",
        "        #print(files)\n",
        "        for f in files:\n",
        "        \tif f.find('png') != -1 and f.find('nand') != -1 and v_nand:\n",
        "        \t\ts = '/content/CNN/-0.28_2/nand/'+f\n",
        "        \t\tuse.append(s)\n",
        "        \t\tv = 6\t\t\n",
        "        \t\tif again:\n",
        "        \t\t\tv = 2\n",
        "        \t\tif flag % 4 == 0:\n",
        "        \t\t\ttest_labels.append(6)\n",
        "        \t\telse:\n",
        "        \t\t\ttrain_labels.append(6)\n",
        "        \t\tflag += 1\n",
        "\n",
        "    \n",
        "   \n",
        "    flag = 0  \n",
        "    for u in use:\n",
        "    \timg2 = np.zeros([400, 400, 3],dtype=np.uint8)\n",
        "    \timg = cv2.imread(u)\n",
        "    \tprint('val of u',u)\n",
        "    \t#print(np.shape(img))\t\n",
        "    \tfor i in range(400):\n",
        "    \t\tfor j in range(400):\n",
        "    \t\t\timg2[(i, j, 0)] = img[(i, j, 0)] \n",
        "    \t\t\timg2[(i, j, 1)] = img[(i, j, 1)] \n",
        "    \t\t\timg2[(i, j, 2)] = img[(i, j, 2)] \n",
        "\n",
        "    \timg2 = cv2.resize(img2, (80, 80))\n",
        "    \tif flag % 4 == 0:\n",
        "    \t\ttest_images.append(img2)\n",
        "    \telse:\n",
        "    \t\ttrain_images.append(img2)\n",
        "\t\t\t\n",
        "    \tflag += 1\n",
        "\n",
        "    \t#break\n",
        "    \t#print(img)\n",
        "    #print(test_images)   \n",
        " \n",
        "    train_images =  np.array(train_images)  \n",
        "    test_images =  np.array(test_images) \n",
        "\n",
        "    train_labels =  np.array(train_labels)  \n",
        "    test_labels =  np.array(test_labels)  \n",
        "\n",
        "    print(len(train_labels), len(test_labels))\n",
        "    \n",
        "    return train_images, train_labels, test_images, test_labels\n",
        "    \n",
        "#dataset()\n",
        "print('a')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_images, train_labels, test_images, test_labels = dataset(False)"
      ],
      "metadata": {
        "id": "rbgBmjciNyyW"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def desenha():\n",
        "  plt.figure(figsize=(20,20))\n",
        "  for i in range(0,30,2):\n",
        "      plt.subplot(5,5,int(i/2)+1)\n",
        "      plt.xticks([])\n",
        "      plt.yticks([])\n",
        "      plt.grid(False)\n",
        "      plt.imshow(test_images[i])\n",
        "      # The CIFAR labels happen to be arrays, \n",
        "      # which is why you need the extra index\n",
        "      plt.xlabel(test_labels[i])\n",
        "  plt.show()\n",
        "\n",
        "#desenha()"
      ],
      "metadata": {
        "id": "YuQAwVBJMtAh"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def x(again):\n",
        "    \n",
        "  train_images, train_labels, test_images, test_labels = dataset(again)\n",
        "\n",
        "\n",
        "  print(type(train_images[0]))\n",
        "\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(80, 80, 3)))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu')) #64\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.Dense(10))\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  history = model.fit(train_images, train_labels, epochs=100, \n",
        "                      validation_data=(test_images, test_labels))\n",
        "  \n",
        "  return history.history['val_accuracy']\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6NhWbf_u_nsQ"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v_and = True\n",
        "v_or = False\n",
        "v_xor = False\n",
        "v_xnor = False\n",
        "v_nand = False\n",
        "v_nor = True\n",
        "\n",
        "lin_1 = x(False)\n",
        "\n",
        "v_and = False\n",
        "v_or = False\n",
        "v_xor = True\n",
        "v_xnor = True\n",
        "v_nand = False\n",
        "v_nor = False\n",
        "\n",
        "lin_2 = x(False)\n",
        "\n",
        "v_and = False\n",
        "v_or = True\n",
        "v_xor = False\n",
        "v_xnor = False\n",
        "v_nand = True\n",
        "v_nor = False\n",
        "\n",
        "lin_3 = x(False)\n",
        "\n",
        "v_and = True\n",
        "v_or = True\n",
        "v_xor = True\n",
        "v_xnor = True\n",
        "v_nand = True\n",
        "v_nor = True\n",
        "\n",
        "lin_4 = x(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDIw5aDb7rVp",
        "outputId": "a5f429a5-b100-4c4a-8cd0-fe4241b13ca3"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val of u /content/CNN/-0.28_2/and/and18.png\n",
            "val of u /content/CNN/-0.28_2/and/and6.png\n",
            "val of u /content/CNN/-0.28_2/and/and3.png\n",
            "val of u /content/CNN/-0.28_2/and/and9.png\n",
            "val of u /content/CNN/-0.28_2/and/and1.png\n",
            "val of u /content/CNN/-0.28_2/and/and14.png\n",
            "val of u /content/CNN/-0.28_2/and/and15.png\n",
            "val of u /content/CNN/-0.28_2/and/and13.png\n",
            "val of u /content/CNN/-0.28_2/and/and8.png\n",
            "val of u /content/CNN/-0.28_2/and/and16.png\n",
            "val of u /content/CNN/-0.28_2/and/and11.png\n",
            "val of u /content/CNN/-0.28_2/and/and4.png\n",
            "val of u /content/CNN/-0.28_2/and/and7.png\n",
            "val of u /content/CNN/-0.28_2/and/and10.png\n",
            "val of u /content/CNN/-0.28_2/and/and2.png\n",
            "val of u /content/CNN/-0.28_2/and/and5.png\n",
            "val of u /content/CNN/-0.28_2/and/and12.png\n",
            "val of u /content/CNN/-0.28_2/and/and17.png\n",
            "val of u /content/CNN/-0.28_2/and/and20.png\n",
            "val of u /content/CNN/-0.28_2/and/and19.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor2.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor5.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor13.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor1.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor14.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor12.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor19.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor3.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor10.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor15.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor20.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor4.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor11.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor7.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor16.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor9.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor8.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor17.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor6.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor18.png\n",
            "30 10\n",
            "<class 'numpy.ndarray'>\n",
            "Model: \"sequential_42\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_168 (Conv2D)         (None, 78, 78, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_126 (MaxPooli  (None, 39, 39, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_169 (Conv2D)         (None, 37, 37, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_127 (MaxPooli  (None, 18, 18, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_170 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_128 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_171 (Conv2D)         (None, 6, 6, 32)          36896     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 130,144\n",
            "Trainable params: 130,144\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_42\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_168 (Conv2D)         (None, 78, 78, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_126 (MaxPooli  (None, 39, 39, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_169 (Conv2D)         (None, 37, 37, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_127 (MaxPooli  (None, 18, 18, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_170 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_128 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_171 (Conv2D)         (None, 6, 6, 32)          36896     \n",
            "                                                                 \n",
            " flatten_42 (Flatten)        (None, 1152)              0         \n",
            "                                                                 \n",
            " dense_84 (Dense)            (None, 128)               147584    \n",
            "                                                                 \n",
            " dense_85 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 279,018\n",
            "Trainable params: 279,018\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 104.4836 - accuracy: 0.0000e+00 - val_loss: 11.1541 - val_accuracy: 0.2000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 278ms/step - loss: 10.6001 - accuracy: 0.3667 - val_loss: 67.0029 - val_accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 67.5658 - accuracy: 0.5000 - val_loss: 2.9361 - val_accuracy: 0.7000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 278ms/step - loss: 1.7377 - accuracy: 0.8333 - val_loss: 49.6892 - val_accuracy: 0.5000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 51.1369 - accuracy: 0.5000 - val_loss: 21.9108 - val_accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 22.8162 - accuracy: 0.5000 - val_loss: 13.1088 - val_accuracy: 0.5000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 12.5790 - accuracy: 0.5000 - val_loss: 13.0031 - val_accuracy: 0.5000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 12.4170 - accuracy: 0.5000 - val_loss: 1.7623 - val_accuracy: 0.8000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 1.2265 - accuracy: 0.9000 - val_loss: 3.9618 - val_accuracy: 0.8000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 264ms/step - loss: 3.1749 - accuracy: 0.7000 - val_loss: 4.3048 - val_accuracy: 0.7000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 265ms/step - loss: 3.3438 - accuracy: 0.7000 - val_loss: 1.8831 - val_accuracy: 0.7000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 0.8711 - accuracy: 0.9000 - val_loss: 1.5109 - val_accuracy: 0.9000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 1.5836 - accuracy: 0.8333 - val_loss: 1.0074 - val_accuracy: 0.9000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 265ms/step - loss: 1.0077 - accuracy: 0.9333 - val_loss: 0.8142 - val_accuracy: 0.8000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 278ms/step - loss: 0.4683 - accuracy: 0.8667 - val_loss: 1.4039 - val_accuracy: 0.8000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.5778 - accuracy: 0.8667 - val_loss: 1.5199 - val_accuracy: 0.8000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 0.7436 - accuracy: 0.8667 - val_loss: 1.0222 - val_accuracy: 0.8000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.4755 - accuracy: 0.8333 - val_loss: 0.3902 - val_accuracy: 0.9000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 0.2009 - accuracy: 0.9333 - val_loss: 0.1771 - val_accuracy: 0.9000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 283ms/step - loss: 0.2868 - accuracy: 0.9333 - val_loss: 0.2600 - val_accuracy: 0.9000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 265ms/step - loss: 0.3372 - accuracy: 0.9333 - val_loss: 0.2561 - val_accuracy: 0.9000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 267ms/step - loss: 0.2762 - accuracy: 0.9333 - val_loss: 0.1497 - val_accuracy: 0.9000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 265ms/step - loss: 0.1446 - accuracy: 0.9667 - val_loss: 0.0562 - val_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 268ms/step - loss: 0.0477 - accuracy: 0.9667 - val_loss: 0.0553 - val_accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 0.0742 - accuracy: 0.9667 - val_loss: 0.0699 - val_accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 269ms/step - loss: 0.1145 - accuracy: 0.9667 - val_loss: 0.0559 - val_accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 0.0793 - accuracy: 0.9667 - val_loss: 0.0423 - val_accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.0705 - val_accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 280ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.1473 - val_accuracy: 0.9000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 0.9000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.2771 - val_accuracy: 0.9000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.2609 - val_accuracy: 0.9000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 269ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 280ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.1627 - val_accuracy: 0.9000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 287ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.1228 - val_accuracy: 0.9000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0997 - val_accuracy: 0.9000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 278ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0965 - val_accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 277ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.1057 - val_accuracy: 0.9000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.1156 - val_accuracy: 0.9000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 277ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.1241 - val_accuracy: 0.9000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1332 - val_accuracy: 0.9000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1455 - val_accuracy: 0.9000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.8000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 268ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.9000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2246 - val_accuracy: 0.9000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2593 - val_accuracy: 0.9000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 9.7040e-04 - accuracy: 1.0000 - val_loss: 0.2946 - val_accuracy: 0.9000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 266ms/step - loss: 9.4460e-04 - accuracy: 1.0000 - val_loss: 0.3278 - val_accuracy: 0.9000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 279ms/step - loss: 9.6613e-04 - accuracy: 1.0000 - val_loss: 0.3568 - val_accuracy: 0.9000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3823 - val_accuracy: 0.9000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4037 - val_accuracy: 0.9000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4207 - val_accuracy: 0.9000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4330 - val_accuracy: 0.9000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4401 - val_accuracy: 0.9000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 268ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4438 - val_accuracy: 0.9000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 281ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4440 - val_accuracy: 0.9000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 278ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4410 - val_accuracy: 0.9000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 266ms/step - loss: 9.5370e-04 - accuracy: 1.0000 - val_loss: 0.4359 - val_accuracy: 0.9000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 261ms/step - loss: 8.7830e-04 - accuracy: 1.0000 - val_loss: 0.4290 - val_accuracy: 0.9000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 8.0619e-04 - accuracy: 1.0000 - val_loss: 0.4207 - val_accuracy: 0.9000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 7.3910e-04 - accuracy: 1.0000 - val_loss: 0.4113 - val_accuracy: 0.9000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 6.8351e-04 - accuracy: 1.0000 - val_loss: 0.4019 - val_accuracy: 0.9000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 6.3573e-04 - accuracy: 1.0000 - val_loss: 0.3923 - val_accuracy: 0.9000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 265ms/step - loss: 5.9571e-04 - accuracy: 1.0000 - val_loss: 0.3829 - val_accuracy: 0.9000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 5.6253e-04 - accuracy: 1.0000 - val_loss: 0.3735 - val_accuracy: 0.9000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 269ms/step - loss: 5.3523e-04 - accuracy: 1.0000 - val_loss: 0.3648 - val_accuracy: 0.9000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 5.1270e-04 - accuracy: 1.0000 - val_loss: 0.3566 - val_accuracy: 0.9000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 264ms/step - loss: 4.9400e-04 - accuracy: 1.0000 - val_loss: 0.3490 - val_accuracy: 0.9000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 264ms/step - loss: 4.7839e-04 - accuracy: 1.0000 - val_loss: 0.3420 - val_accuracy: 0.9000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 267ms/step - loss: 4.6510e-04 - accuracy: 1.0000 - val_loss: 0.3355 - val_accuracy: 0.9000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 283ms/step - loss: 4.5393e-04 - accuracy: 1.0000 - val_loss: 0.3296 - val_accuracy: 0.9000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 277ms/step - loss: 4.4449e-04 - accuracy: 1.0000 - val_loss: 0.3242 - val_accuracy: 0.9000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 263ms/step - loss: 4.3660e-04 - accuracy: 1.0000 - val_loss: 0.3192 - val_accuracy: 0.9000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 4.2985e-04 - accuracy: 1.0000 - val_loss: 0.3145 - val_accuracy: 0.9000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 4.2390e-04 - accuracy: 1.0000 - val_loss: 0.3104 - val_accuracy: 0.9000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 266ms/step - loss: 4.1857e-04 - accuracy: 1.0000 - val_loss: 0.3068 - val_accuracy: 0.9000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 264ms/step - loss: 4.1367e-04 - accuracy: 1.0000 - val_loss: 0.3036 - val_accuracy: 0.9000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 4.0904e-04 - accuracy: 1.0000 - val_loss: 0.3008 - val_accuracy: 0.9000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 269ms/step - loss: 4.0459e-04 - accuracy: 1.0000 - val_loss: 0.2984 - val_accuracy: 0.9000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 266ms/step - loss: 4.0017e-04 - accuracy: 1.0000 - val_loss: 0.2964 - val_accuracy: 0.9000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 268ms/step - loss: 3.9579e-04 - accuracy: 1.0000 - val_loss: 0.2946 - val_accuracy: 0.9000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 3.9152e-04 - accuracy: 1.0000 - val_loss: 0.2933 - val_accuracy: 0.9000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 3.8718e-04 - accuracy: 1.0000 - val_loss: 0.2923 - val_accuracy: 0.9000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 263ms/step - loss: 3.8282e-04 - accuracy: 1.0000 - val_loss: 0.2915 - val_accuracy: 0.9000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 3.7842e-04 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.9000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 277ms/step - loss: 3.7398e-04 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.9000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 3.6956e-04 - accuracy: 1.0000 - val_loss: 0.2905 - val_accuracy: 0.9000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 3.6512e-04 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.9000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 282ms/step - loss: 3.6076e-04 - accuracy: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.9000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 3.5655e-04 - accuracy: 1.0000 - val_loss: 0.2912 - val_accuracy: 0.9000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 261ms/step - loss: 3.5239e-04 - accuracy: 1.0000 - val_loss: 0.2918 - val_accuracy: 0.9000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 269ms/step - loss: 3.4831e-04 - accuracy: 1.0000 - val_loss: 0.2924 - val_accuracy: 0.9000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 3.4433e-04 - accuracy: 1.0000 - val_loss: 0.2931 - val_accuracy: 0.9000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 3.4047e-04 - accuracy: 1.0000 - val_loss: 0.2939 - val_accuracy: 0.9000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 261ms/step - loss: 3.3674e-04 - accuracy: 1.0000 - val_loss: 0.2948 - val_accuracy: 0.9000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 3.3313e-04 - accuracy: 1.0000 - val_loss: 0.2956 - val_accuracy: 0.9000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 3.2965e-04 - accuracy: 1.0000 - val_loss: 0.2965 - val_accuracy: 0.9000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 3.2628e-04 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.9000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 281ms/step - loss: 3.2312e-04 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.9000\n",
            "val of u /content/CNN/-0.28_2/xor/xor5.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor13.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor16.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor7.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor12.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor6.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor15.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor19.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor9.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor11.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor8.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor18.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor4.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor1.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor20.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor3.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor2.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor17.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor14.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor10.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor10.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor2.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor1.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor14.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor4.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor13.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor6.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor7.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor5.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor20.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor8.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor16.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor15.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor11.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor17.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor12.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor19.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor3.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor18.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor9.png\n",
            "30 10\n",
            "<class 'numpy.ndarray'>\n",
            "Model: \"sequential_43\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_172 (Conv2D)         (None, 78, 78, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_129 (MaxPooli  (None, 39, 39, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_173 (Conv2D)         (None, 37, 37, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_130 (MaxPooli  (None, 18, 18, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_174 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_131 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_175 (Conv2D)         (None, 6, 6, 32)          36896     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 130,144\n",
            "Trainable params: 130,144\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_43\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_172 (Conv2D)         (None, 78, 78, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_129 (MaxPooli  (None, 39, 39, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_173 (Conv2D)         (None, 37, 37, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_130 (MaxPooli  (None, 18, 18, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_174 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_131 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_175 (Conv2D)         (None, 6, 6, 32)          36896     \n",
            "                                                                 \n",
            " flatten_43 (Flatten)        (None, 1152)              0         \n",
            "                                                                 \n",
            " dense_86 (Dense)            (None, 128)               147584    \n",
            "                                                                 \n",
            " dense_87 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 279,018\n",
            "Trainable params: 279,018\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 28.6571 - accuracy: 0.1000 - val_loss: 6.3283 - val_accuracy: 0.4000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 267ms/step - loss: 6.1209 - accuracy: 0.3333 - val_loss: 47.4753 - val_accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 46.5222 - accuracy: 0.5000 - val_loss: 18.1917 - val_accuracy: 0.5000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 17.1574 - accuracy: 0.5000 - val_loss: 11.0636 - val_accuracy: 0.5000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 10.2203 - accuracy: 0.5000 - val_loss: 4.8689 - val_accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 269ms/step - loss: 3.7261 - accuracy: 0.5000 - val_loss: 3.1567 - val_accuracy: 0.7000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 1.8362 - accuracy: 0.7667 - val_loss: 3.7721 - val_accuracy: 0.6000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 2.1851 - accuracy: 0.7333 - val_loss: 1.4315 - val_accuracy: 0.6000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 0.8758 - accuracy: 0.7000 - val_loss: 0.9460 - val_accuracy: 0.6000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 0.6043 - accuracy: 0.8000 - val_loss: 1.3648 - val_accuracy: 0.7000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 268ms/step - loss: 0.7499 - accuracy: 0.7667 - val_loss: 1.0107 - val_accuracy: 0.7000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.4389 - accuracy: 0.8667 - val_loss: 0.7555 - val_accuracy: 0.5000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 277ms/step - loss: 0.3034 - accuracy: 0.9000 - val_loss: 0.8255 - val_accuracy: 0.6000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 0.2477 - accuracy: 0.8667 - val_loss: 0.9605 - val_accuracy: 0.7000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.2535 - accuracy: 0.8667 - val_loss: 0.9273 - val_accuracy: 0.7000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 278ms/step - loss: 0.1942 - accuracy: 0.9000 - val_loss: 1.0124 - val_accuracy: 0.6000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 265ms/step - loss: 0.2082 - accuracy: 0.9000 - val_loss: 0.8946 - val_accuracy: 0.7000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 0.1060 - accuracy: 1.0000 - val_loss: 0.9090 - val_accuracy: 0.7000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.1288 - accuracy: 0.9667 - val_loss: 0.9040 - val_accuracy: 0.8000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 266ms/step - loss: 0.1022 - accuracy: 0.9667 - val_loss: 0.8898 - val_accuracy: 0.8000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.0653 - accuracy: 1.0000 - val_loss: 0.9572 - val_accuracy: 0.7000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 269ms/step - loss: 0.1084 - accuracy: 0.9667 - val_loss: 0.9296 - val_accuracy: 0.8000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 281ms/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 1.0146 - val_accuracy: 0.8000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 0.0715 - accuracy: 1.0000 - val_loss: 0.9949 - val_accuracy: 0.8000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.0516 - accuracy: 1.0000 - val_loss: 0.9525 - val_accuracy: 0.8000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 0.9949 - val_accuracy: 0.8000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 1.0204 - val_accuracy: 0.7000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.9877 - val_accuracy: 0.8000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.9774 - val_accuracy: 0.8000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 280ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.9925 - val_accuracy: 0.8000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.9920 - val_accuracy: 0.8000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.9827 - val_accuracy: 0.8000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.9884 - val_accuracy: 0.8000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 267ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.0071 - val_accuracy: 0.8000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.0187 - val_accuracy: 0.8000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 280ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 1.0088 - val_accuracy: 0.8000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.9900 - val_accuracy: 0.8000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.9795 - val_accuracy: 0.8000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.9817 - val_accuracy: 0.8000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.9893 - val_accuracy: 0.8000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 279ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.9964 - val_accuracy: 0.8000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.9957 - val_accuracy: 0.8000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.9831 - val_accuracy: 0.8000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.9724 - val_accuracy: 0.8000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.9658 - val_accuracy: 0.8000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 384ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.9633 - val_accuracy: 0.8000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.9633 - val_accuracy: 0.8000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 268ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.9653 - val_accuracy: 0.8000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 268ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.9680 - val_accuracy: 0.8000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 283ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.9719 - val_accuracy: 0.8000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 277ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.9759 - val_accuracy: 0.8000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 265ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.9840 - val_accuracy: 0.8000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.9987 - val_accuracy: 0.8000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.0018 - val_accuracy: 0.8000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 283ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.0015 - val_accuracy: 0.8000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.9999 - val_accuracy: 0.8000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 282ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.9967 - val_accuracy: 0.8000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 267ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9916 - val_accuracy: 0.8000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 269ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.9870 - val_accuracy: 0.8000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9802 - val_accuracy: 0.8000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 278ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9716 - val_accuracy: 0.8000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9617 - val_accuracy: 0.8000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 281ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9513 - val_accuracy: 0.8000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 282ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9462 - val_accuracy: 0.8000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 265ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9426 - val_accuracy: 0.8000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 262ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9386 - val_accuracy: 0.8000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9349 - val_accuracy: 0.8000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9323 - val_accuracy: 0.8000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9316 - val_accuracy: 0.8000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 269ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9339 - val_accuracy: 0.8000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 9.8678e-04 - accuracy: 1.0000 - val_loss: 0.9382 - val_accuracy: 0.8000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 9.4224e-04 - accuracy: 1.0000 - val_loss: 0.9448 - val_accuracy: 0.8000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 9.0169e-04 - accuracy: 1.0000 - val_loss: 0.9510 - val_accuracy: 0.8000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 8.6871e-04 - accuracy: 1.0000 - val_loss: 0.9567 - val_accuracy: 0.8000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 281ms/step - loss: 8.3831e-04 - accuracy: 1.0000 - val_loss: 0.9605 - val_accuracy: 0.8000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 8.0909e-04 - accuracy: 1.0000 - val_loss: 0.9632 - val_accuracy: 0.8000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 278ms/step - loss: 7.8310e-04 - accuracy: 1.0000 - val_loss: 0.9672 - val_accuracy: 0.8000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 280ms/step - loss: 7.6215e-04 - accuracy: 1.0000 - val_loss: 0.9701 - val_accuracy: 0.8000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 7.4144e-04 - accuracy: 1.0000 - val_loss: 0.9715 - val_accuracy: 0.8000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 7.1751e-04 - accuracy: 1.0000 - val_loss: 0.9713 - val_accuracy: 0.8000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 269ms/step - loss: 6.9287e-04 - accuracy: 1.0000 - val_loss: 0.9696 - val_accuracy: 0.8000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 283ms/step - loss: 6.7097e-04 - accuracy: 1.0000 - val_loss: 0.9676 - val_accuracy: 0.8000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 6.5022e-04 - accuracy: 1.0000 - val_loss: 0.9646 - val_accuracy: 0.8000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 6.2946e-04 - accuracy: 1.0000 - val_loss: 0.9608 - val_accuracy: 0.8000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 6.0872e-04 - accuracy: 1.0000 - val_loss: 0.9567 - val_accuracy: 0.8000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 5.8966e-04 - accuracy: 1.0000 - val_loss: 0.9516 - val_accuracy: 0.8000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 5.7170e-04 - accuracy: 1.0000 - val_loss: 0.9461 - val_accuracy: 0.8000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 5.5279e-04 - accuracy: 1.0000 - val_loss: 0.9415 - val_accuracy: 0.8000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 5.3555e-04 - accuracy: 1.0000 - val_loss: 0.9400 - val_accuracy: 0.8000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 5.1842e-04 - accuracy: 1.0000 - val_loss: 0.9406 - val_accuracy: 0.8000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 277ms/step - loss: 5.0228e-04 - accuracy: 1.0000 - val_loss: 0.9417 - val_accuracy: 0.8000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 4.8664e-04 - accuracy: 1.0000 - val_loss: 0.9429 - val_accuracy: 0.8000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 4.7048e-04 - accuracy: 1.0000 - val_loss: 0.9441 - val_accuracy: 0.8000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 267ms/step - loss: 4.5391e-04 - accuracy: 1.0000 - val_loss: 0.9451 - val_accuracy: 0.8000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 4.3894e-04 - accuracy: 1.0000 - val_loss: 0.9455 - val_accuracy: 0.8000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 4.2544e-04 - accuracy: 1.0000 - val_loss: 0.9447 - val_accuracy: 0.8000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 4.1261e-04 - accuracy: 1.0000 - val_loss: 0.9439 - val_accuracy: 0.8000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 4.0039e-04 - accuracy: 1.0000 - val_loss: 0.9428 - val_accuracy: 0.8000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 277ms/step - loss: 3.8825e-04 - accuracy: 1.0000 - val_loss: 0.9421 - val_accuracy: 0.8000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 278ms/step - loss: 3.7644e-04 - accuracy: 1.0000 - val_loss: 0.9419 - val_accuracy: 0.8000\n",
            "val of u /content/CNN/-0.28_2/or/or6.png\n",
            "val of u /content/CNN/-0.28_2/or/or12.png\n",
            "val of u /content/CNN/-0.28_2/or/or10.png\n",
            "val of u /content/CNN/-0.28_2/or/or9.png\n",
            "val of u /content/CNN/-0.28_2/or/or16.png\n",
            "val of u /content/CNN/-0.28_2/or/or18.png\n",
            "val of u /content/CNN/-0.28_2/or/or5.png\n",
            "val of u /content/CNN/-0.28_2/or/or7.png\n",
            "val of u /content/CNN/-0.28_2/or/or14.png\n",
            "val of u /content/CNN/-0.28_2/or/or17.png\n",
            "val of u /content/CNN/-0.28_2/or/or20.png\n",
            "val of u /content/CNN/-0.28_2/or/or2.png\n",
            "val of u /content/CNN/-0.28_2/or/or13.png\n",
            "val of u /content/CNN/-0.28_2/or/or11.png\n",
            "val of u /content/CNN/-0.28_2/or/or4.png\n",
            "val of u /content/CNN/-0.28_2/or/or8.png\n",
            "val of u /content/CNN/-0.28_2/or/or15.png\n",
            "val of u /content/CNN/-0.28_2/or/or3.png\n",
            "val of u /content/CNN/-0.28_2/or/or1.png\n",
            "val of u /content/CNN/-0.28_2/or/or19.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand11.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand13.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand19.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand2.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand3.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand16.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand15.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand14.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand18.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand4.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand12.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand17.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand8.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand1.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand7.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand5.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand10.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand9.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand20.png\n",
            "29 10\n",
            "<class 'numpy.ndarray'>\n",
            "Model: \"sequential_44\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_176 (Conv2D)         (None, 78, 78, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_132 (MaxPooli  (None, 39, 39, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_177 (Conv2D)         (None, 37, 37, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_133 (MaxPooli  (None, 18, 18, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_178 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_134 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_179 (Conv2D)         (None, 6, 6, 32)          36896     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 130,144\n",
            "Trainable params: 130,144\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_44\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_176 (Conv2D)         (None, 78, 78, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_132 (MaxPooli  (None, 39, 39, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_177 (Conv2D)         (None, 37, 37, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_133 (MaxPooli  (None, 18, 18, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_178 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_134 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_179 (Conv2D)         (None, 6, 6, 32)          36896     \n",
            "                                                                 \n",
            " flatten_44 (Flatten)        (None, 1152)              0         \n",
            "                                                                 \n",
            " dense_88 (Dense)            (None, 128)               147584    \n",
            "                                                                 \n",
            " dense_89 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 279,018\n",
            "Trainable params: 279,018\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 54.6181 - accuracy: 0.0000e+00 - val_loss: 12.1275 - val_accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 12.5656 - accuracy: 0.4828 - val_loss: 74.9019 - val_accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 265ms/step - loss: 77.9585 - accuracy: 0.5172 - val_loss: 19.7321 - val_accuracy: 0.5000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 263ms/step - loss: 20.3691 - accuracy: 0.5172 - val_loss: 16.2232 - val_accuracy: 0.5000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 16.5044 - accuracy: 0.4828 - val_loss: 9.4364 - val_accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 9.7144 - accuracy: 0.4828 - val_loss: 5.3471 - val_accuracy: 0.5000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 5.3765 - accuracy: 0.5172 - val_loss: 6.0971 - val_accuracy: 0.5000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 264ms/step - loss: 5.0129 - accuracy: 0.5172 - val_loss: 1.0968 - val_accuracy: 0.8000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 1.0376 - accuracy: 0.7241 - val_loss: 0.8881 - val_accuracy: 0.6000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 2.7029 - accuracy: 0.5517 - val_loss: 0.7719 - val_accuracy: 0.8000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 278ms/step - loss: 0.5012 - accuracy: 0.7931 - val_loss: 2.6615 - val_accuracy: 0.5000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 269ms/step - loss: 1.5916 - accuracy: 0.5517 - val_loss: 1.6257 - val_accuracy: 0.6000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 269ms/step - loss: 0.9823 - accuracy: 0.6897 - val_loss: 0.2096 - val_accuracy: 0.9000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 265ms/step - loss: 0.2178 - accuracy: 0.9310 - val_loss: 0.0791 - val_accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 264ms/step - loss: 1.0776 - accuracy: 0.6552 - val_loss: 0.0747 - val_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 277ms/step - loss: 0.5159 - accuracy: 0.7931 - val_loss: 0.3238 - val_accuracy: 0.9000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 268ms/step - loss: 0.1523 - accuracy: 0.8966 - val_loss: 0.8356 - val_accuracy: 0.7000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.5137 - accuracy: 0.8276 - val_loss: 0.9171 - val_accuracy: 0.7000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 269ms/step - loss: 0.5130 - accuracy: 0.8276 - val_loss: 0.4983 - val_accuracy: 0.8000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 0.2122 - accuracy: 0.8966 - val_loss: 0.2122 - val_accuracy: 0.9000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 0.0879 - accuracy: 0.9655 - val_loss: 0.2318 - val_accuracy: 0.8000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 262ms/step - loss: 0.2321 - accuracy: 0.8621 - val_loss: 0.2378 - val_accuracy: 0.8000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 267ms/step - loss: 0.2076 - accuracy: 0.8621 - val_loss: 0.2372 - val_accuracy: 0.9000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 0.0629 - accuracy: 1.0000 - val_loss: 0.3782 - val_accuracy: 0.9000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 263ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.5330 - val_accuracy: 0.8000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 266ms/step - loss: 0.0509 - accuracy: 0.9655 - val_loss: 0.6180 - val_accuracy: 0.8000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.0702 - accuracy: 0.9655 - val_loss: 0.6142 - val_accuracy: 0.8000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 266ms/step - loss: 0.0629 - accuracy: 0.9655 - val_loss: 0.5233 - val_accuracy: 0.8000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 269ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.3895 - val_accuracy: 0.8000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 264ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.2678 - val_accuracy: 0.9000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.1723 - val_accuracy: 0.9000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.1146 - val_accuracy: 0.9000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 263ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 261ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.0991 - val_accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 268ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.1299 - val_accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 268ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.1785 - val_accuracy: 0.9000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 266ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.2417 - val_accuracy: 0.8000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.3099 - val_accuracy: 0.7000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 260ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.3701 - val_accuracy: 0.7000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 259ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.4073 - val_accuracy: 0.7000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 268ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.4158 - val_accuracy: 0.7000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.4001 - val_accuracy: 0.7000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 264ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.3667 - val_accuracy: 0.7000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 279ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.3248 - val_accuracy: 0.7000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 267ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2822 - val_accuracy: 0.8000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2450 - val_accuracy: 0.9000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 265ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2150 - val_accuracy: 0.9000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 262ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 283ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 0.9000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 263ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1651 - val_accuracy: 0.9000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 261ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1590 - val_accuracy: 0.9000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1571 - val_accuracy: 0.9000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1591 - val_accuracy: 0.9000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 268ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1639 - val_accuracy: 0.9000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1712 - val_accuracy: 0.9000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1803 - val_accuracy: 0.9000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 0.9000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 269ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2105 - val_accuracy: 0.9000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2195 - val_accuracy: 0.9000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 263ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2265 - val_accuracy: 0.9000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 268ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 0.9000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 280ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2340 - val_accuracy: 0.9000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 263ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2343 - val_accuracy: 0.8000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 257ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2324 - val_accuracy: 0.8000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.8000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 278ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2236 - val_accuracy: 0.8000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 265ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2175 - val_accuracy: 0.8000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 264ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.8000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 267ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 0.8000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 269ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.8000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 257ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.8000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 279ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1861 - val_accuracy: 0.8000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 264ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 0.8000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 279ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 0.8000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1752 - val_accuracy: 0.8000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 279ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1734 - val_accuracy: 0.8000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 282ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1723 - val_accuracy: 0.8000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 0.8000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 266ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1724 - val_accuracy: 0.8000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 268ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1734 - val_accuracy: 0.8000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 277ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1749 - val_accuracy: 0.8000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 278ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1769 - val_accuracy: 0.8000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 258ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 0.8000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 263ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 0.8000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1839 - val_accuracy: 0.8000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 262ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1864 - val_accuracy: 0.8000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 263ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1886 - val_accuracy: 0.8000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1907 - val_accuracy: 0.8000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 268ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.8000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 262ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1939 - val_accuracy: 0.8000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 0.8000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 0.8000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.8000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1958 - val_accuracy: 0.8000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 268ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 0.8000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.8000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 268ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1935 - val_accuracy: 0.8000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.8000\n",
            "val of u /content/CNN/-0.28_2/and/and18.png\n",
            "val of u /content/CNN/-0.28_2/and/and6.png\n",
            "val of u /content/CNN/-0.28_2/and/and3.png\n",
            "val of u /content/CNN/-0.28_2/and/and9.png\n",
            "val of u /content/CNN/-0.28_2/and/and1.png\n",
            "val of u /content/CNN/-0.28_2/and/and14.png\n",
            "val of u /content/CNN/-0.28_2/and/and15.png\n",
            "val of u /content/CNN/-0.28_2/and/and13.png\n",
            "val of u /content/CNN/-0.28_2/and/and8.png\n",
            "val of u /content/CNN/-0.28_2/and/and16.png\n",
            "val of u /content/CNN/-0.28_2/and/and11.png\n",
            "val of u /content/CNN/-0.28_2/and/and4.png\n",
            "val of u /content/CNN/-0.28_2/and/and7.png\n",
            "val of u /content/CNN/-0.28_2/and/and10.png\n",
            "val of u /content/CNN/-0.28_2/and/and2.png\n",
            "val of u /content/CNN/-0.28_2/and/and5.png\n",
            "val of u /content/CNN/-0.28_2/and/and12.png\n",
            "val of u /content/CNN/-0.28_2/and/and17.png\n",
            "val of u /content/CNN/-0.28_2/and/and20.png\n",
            "val of u /content/CNN/-0.28_2/and/and19.png\n",
            "val of u /content/CNN/-0.28_2/or/or6.png\n",
            "val of u /content/CNN/-0.28_2/or/or12.png\n",
            "val of u /content/CNN/-0.28_2/or/or10.png\n",
            "val of u /content/CNN/-0.28_2/or/or9.png\n",
            "val of u /content/CNN/-0.28_2/or/or16.png\n",
            "val of u /content/CNN/-0.28_2/or/or18.png\n",
            "val of u /content/CNN/-0.28_2/or/or5.png\n",
            "val of u /content/CNN/-0.28_2/or/or7.png\n",
            "val of u /content/CNN/-0.28_2/or/or14.png\n",
            "val of u /content/CNN/-0.28_2/or/or17.png\n",
            "val of u /content/CNN/-0.28_2/or/or20.png\n",
            "val of u /content/CNN/-0.28_2/or/or2.png\n",
            "val of u /content/CNN/-0.28_2/or/or13.png\n",
            "val of u /content/CNN/-0.28_2/or/or11.png\n",
            "val of u /content/CNN/-0.28_2/or/or4.png\n",
            "val of u /content/CNN/-0.28_2/or/or8.png\n",
            "val of u /content/CNN/-0.28_2/or/or15.png\n",
            "val of u /content/CNN/-0.28_2/or/or3.png\n",
            "val of u /content/CNN/-0.28_2/or/or1.png\n",
            "val of u /content/CNN/-0.28_2/or/or19.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor5.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor13.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor16.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor7.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor12.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor6.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor15.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor19.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor9.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor11.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor8.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor18.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor4.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor1.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor20.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor3.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor2.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor17.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor14.png\n",
            "val of u /content/CNN/-0.28_2/xor/xor10.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor10.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor2.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor1.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor14.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor4.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor13.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor6.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor7.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor5.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor20.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor8.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor16.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor15.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor11.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor17.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor12.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor19.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor3.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor18.png\n",
            "val of u /content/CNN/-0.28_2/xnor/xnor9.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor2.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor5.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor13.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor1.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor14.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor12.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor19.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor3.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor10.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor15.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor20.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor4.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor11.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor7.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor16.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor9.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor8.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor17.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor6.png\n",
            "val of u /content/CNN/-0.28_2/nor/nor18.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand11.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand13.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand19.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand2.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand3.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand16.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand15.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand14.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand18.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand4.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand12.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand17.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand8.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand1.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand7.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand5.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand10.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand9.png\n",
            "val of u /content/CNN/-0.28_2/nand/nand20.png\n",
            "89 30\n",
            "<class 'numpy.ndarray'>\n",
            "Model: \"sequential_45\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_180 (Conv2D)         (None, 78, 78, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_135 (MaxPooli  (None, 39, 39, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_181 (Conv2D)         (None, 37, 37, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_136 (MaxPooli  (None, 18, 18, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_182 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_137 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_183 (Conv2D)         (None, 6, 6, 32)          36896     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 130,144\n",
            "Trainable params: 130,144\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_45\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_180 (Conv2D)         (None, 78, 78, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_135 (MaxPooli  (None, 39, 39, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_181 (Conv2D)         (None, 37, 37, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_136 (MaxPooli  (None, 18, 18, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_182 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_137 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_183 (Conv2D)         (None, 6, 6, 32)          36896     \n",
            "                                                                 \n",
            " flatten_45 (Flatten)        (None, 1152)              0         \n",
            "                                                                 \n",
            " dense_90 (Dense)            (None, 128)               147584    \n",
            "                                                                 \n",
            " dense_91 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 279,018\n",
            "Trainable params: 279,018\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "3/3 [==============================] - 1s 329ms/step - loss: 83.6692 - accuracy: 0.2360 - val_loss: 37.8716 - val_accuracy: 0.1667\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 20.6165 - accuracy: 0.1685 - val_loss: 3.1848 - val_accuracy: 0.3000\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 2.4350 - accuracy: 0.3483 - val_loss: 1.7093 - val_accuracy: 0.5667\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 1.4622 - accuracy: 0.4607 - val_loss: 1.5064 - val_accuracy: 0.4333\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 1.3540 - accuracy: 0.4045 - val_loss: 1.2571 - val_accuracy: 0.5333\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 1.2008 - accuracy: 0.4944 - val_loss: 1.0738 - val_accuracy: 0.6667\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 0.9708 - accuracy: 0.6180 - val_loss: 1.2784 - val_accuracy: 0.4333\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 1s 272ms/step - loss: 0.9165 - accuracy: 0.6517 - val_loss: 1.2991 - val_accuracy: 0.5000\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 1s 272ms/step - loss: 0.7507 - accuracy: 0.7191 - val_loss: 1.0944 - val_accuracy: 0.6667\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 0.6235 - accuracy: 0.7640 - val_loss: 1.1900 - val_accuracy: 0.6000\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 1s 264ms/step - loss: 0.6095 - accuracy: 0.7978 - val_loss: 1.3160 - val_accuracy: 0.5333\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 1s 261ms/step - loss: 0.6114 - accuracy: 0.7640 - val_loss: 1.3445 - val_accuracy: 0.5667\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 0.4610 - accuracy: 0.8539 - val_loss: 1.1634 - val_accuracy: 0.6667\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 0.3094 - accuracy: 0.9101 - val_loss: 1.4475 - val_accuracy: 0.7667\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 0.3222 - accuracy: 0.9213 - val_loss: 1.5042 - val_accuracy: 0.6667\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 0.2204 - accuracy: 0.9438 - val_loss: 1.3557 - val_accuracy: 0.7333\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 0.2042 - accuracy: 0.9551 - val_loss: 1.4076 - val_accuracy: 0.7000\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 0.1661 - accuracy: 0.9438 - val_loss: 1.5557 - val_accuracy: 0.6667\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 1s 276ms/step - loss: 0.1466 - accuracy: 0.9551 - val_loss: 1.4994 - val_accuracy: 0.7000\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 0.1139 - accuracy: 1.0000 - val_loss: 1.6766 - val_accuracy: 0.6667\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 0.0891 - accuracy: 0.9888 - val_loss: 1.7110 - val_accuracy: 0.6333\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 0.0986 - accuracy: 0.9775 - val_loss: 1.8479 - val_accuracy: 0.6667\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 0.0666 - accuracy: 0.9888 - val_loss: 1.8101 - val_accuracy: 0.6667\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 0.0477 - accuracy: 1.0000 - val_loss: 1.7731 - val_accuracy: 0.7000\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 1s 267ms/step - loss: 0.0437 - accuracy: 1.0000 - val_loss: 1.9252 - val_accuracy: 0.6667\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 1.9525 - val_accuracy: 0.7333\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 1s 280ms/step - loss: 0.0386 - accuracy: 0.9888 - val_loss: 1.9778 - val_accuracy: 0.7333\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 2.0575 - val_accuracy: 0.7000\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 0.0408 - accuracy: 0.9888 - val_loss: 2.0633 - val_accuracy: 0.7000\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 2.1183 - val_accuracy: 0.7000\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 1s 280ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.2577 - val_accuracy: 0.7000\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.3645 - val_accuracy: 0.7000\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 2.3499 - val_accuracy: 0.7000\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 1s 436ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.3273 - val_accuracy: 0.7000\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 1s 337ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.3191 - val_accuracy: 0.7000\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 1s 272ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.3316 - val_accuracy: 0.7000\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 1s 276ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.3524 - val_accuracy: 0.7333\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.3616 - val_accuracy: 0.7333\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 1s 264ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.3850 - val_accuracy: 0.7000\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.4157 - val_accuracy: 0.7000\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 1s 264ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.4398 - val_accuracy: 0.7000\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.4441 - val_accuracy: 0.7000\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.4506 - val_accuracy: 0.7000\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.4589 - val_accuracy: 0.7000\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 1s 276ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.4640 - val_accuracy: 0.7000\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.4780 - val_accuracy: 0.7000\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 1s 270ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.4931 - val_accuracy: 0.7000\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.5112 - val_accuracy: 0.7000\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.5272 - val_accuracy: 0.7000\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 1s 276ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.5433 - val_accuracy: 0.7000\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.5529 - val_accuracy: 0.7000\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.5599 - val_accuracy: 0.7000\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.5713 - val_accuracy: 0.7000\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 1s 272ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.5780 - val_accuracy: 0.7000\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.5857 - val_accuracy: 0.7000\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.5983 - val_accuracy: 0.7000\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.6101 - val_accuracy: 0.7000\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 1s 267ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.6227 - val_accuracy: 0.7000\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.6315 - val_accuracy: 0.7000\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.6340 - val_accuracy: 0.7000\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.6379 - val_accuracy: 0.7000\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.6489 - val_accuracy: 0.7000\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.6649 - val_accuracy: 0.7000\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.6771 - val_accuracy: 0.7000\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 1s 279ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.6904 - val_accuracy: 0.7000\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 1s 280ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.6982 - val_accuracy: 0.7000\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.7097 - val_accuracy: 0.7000\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.7147 - val_accuracy: 0.7000\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 1s 267ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.7227 - val_accuracy: 0.7000\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 1s 272ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.7308 - val_accuracy: 0.7000\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 1s 264ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.7436 - val_accuracy: 0.7000\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.7568 - val_accuracy: 0.7000\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.7698 - val_accuracy: 0.7000\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.7766 - val_accuracy: 0.7000\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.7815 - val_accuracy: 0.7000\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.7855 - val_accuracy: 0.7000\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.7921 - val_accuracy: 0.7000\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.8001 - val_accuracy: 0.7000\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.8101 - val_accuracy: 0.7000\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.8186 - val_accuracy: 0.7000\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.8248 - val_accuracy: 0.7000\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 9.9302e-04 - accuracy: 1.0000 - val_loss: 2.8304 - val_accuracy: 0.7000\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 9.6408e-04 - accuracy: 1.0000 - val_loss: 2.8364 - val_accuracy: 0.7000\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 9.3591e-04 - accuracy: 1.0000 - val_loss: 2.8408 - val_accuracy: 0.7000\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 1s 270ms/step - loss: 9.1771e-04 - accuracy: 1.0000 - val_loss: 2.8464 - val_accuracy: 0.7000\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 9.0697e-04 - accuracy: 1.0000 - val_loss: 2.8529 - val_accuracy: 0.7000\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 1s 286ms/step - loss: 8.6905e-04 - accuracy: 1.0000 - val_loss: 2.8631 - val_accuracy: 0.7000\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 1s 293ms/step - loss: 8.5830e-04 - accuracy: 1.0000 - val_loss: 2.8729 - val_accuracy: 0.7000\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 8.3398e-04 - accuracy: 1.0000 - val_loss: 2.8830 - val_accuracy: 0.7000\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 8.0968e-04 - accuracy: 1.0000 - val_loss: 2.8884 - val_accuracy: 0.7000\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 1s 276ms/step - loss: 7.9376e-04 - accuracy: 1.0000 - val_loss: 2.8952 - val_accuracy: 0.7000\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 7.7229e-04 - accuracy: 1.0000 - val_loss: 2.8981 - val_accuracy: 0.7000\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 7.5972e-04 - accuracy: 1.0000 - val_loss: 2.9056 - val_accuracy: 0.7000\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 7.3744e-04 - accuracy: 1.0000 - val_loss: 2.9136 - val_accuracy: 0.7000\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 1s 270ms/step - loss: 7.2215e-04 - accuracy: 1.0000 - val_loss: 2.9191 - val_accuracy: 0.7000\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 1s 270ms/step - loss: 6.9841e-04 - accuracy: 1.0000 - val_loss: 2.9242 - val_accuracy: 0.7000\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 6.8382e-04 - accuracy: 1.0000 - val_loss: 2.9317 - val_accuracy: 0.7000\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 6.6927e-04 - accuracy: 1.0000 - val_loss: 2.9379 - val_accuracy: 0.7000\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 6.6186e-04 - accuracy: 1.0000 - val_loss: 2.9427 - val_accuracy: 0.7000\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 6.4560e-04 - accuracy: 1.0000 - val_loss: 2.9503 - val_accuracy: 0.7000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plt.plot(history.history['accuracy'], label='accuracy')\n",
        "\n",
        "plt.plot(lin_4, label = 'total')\n",
        "plt.plot(lin_1, label = 'and_nor')\n",
        "plt.plot(lin_3, label = 'or_nand')\n",
        "plt.plot(lin_2, label = 'xor_xnor')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.0, 1])\n",
        "plt.legend(loc='lower right')\n"
      ],
      "metadata": {
        "id": "5kAYhJbal1Wd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "fb12276b-c6c9-4edf-b620-bb9d425febde"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f93b52c4490>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "#print(test_acc)"
      ],
      "metadata": {
        "id": "FZCUJo14Ds_J"
      },
      "execution_count": 60,
      "outputs": []
    }
  ]
}